{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание: \n",
    "\n",
    "По данному списку фамилий отправить запросы к сайту forebears.io и выгрузить базу данных с количеством их носителей по гендеру в России"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуются 2 реализации: через Selenium и используя только HTTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import lxml\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.page_load_strategy = 'eager'\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "wait = WebDriverWait(driver, 5)\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "\n",
    "def scrape(surname):\n",
    "    global i\n",
    "    i+=1\n",
    "    url = f\"https://forebears.io/surnames/{surname}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    html = driver.page_source\n",
    "    return html\n",
    "\n",
    "\n",
    "def parse(html):\n",
    "    global i\n",
    "    global j\n",
    "    print(i, j)\n",
    "    if not ('bear' in html) and not ('Approximately' in html):\n",
    "        return -1\n",
    "    j += 1\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    table = soup.find('table', {'class': 'table'})\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) >= 2:\n",
    "                country = cols[0].get_text(strip=True)\n",
    "                count = cols[1].get_text(strip=True)\n",
    "                if country.lower() == 'russia' or country.lower() == 'россия':\n",
    "                    return count\n",
    "\n",
    "    return 0\n",
    "\n",
    "def insert_data(index, count, male):\n",
    "    if male == True:\n",
    "        df.at[index, 'male_cnt'] = count\n",
    "    else:\n",
    "        df.at[index, 'female_cnt'] = count\n",
    "\n",
    "k = 0\n",
    "minimum = 0\n",
    "limit = len(df)\n",
    "\n",
    "minimum = max(minimum, 0)\n",
    "limit = max(limit, minimum+1)\n",
    "limit = min(limit, len(df))\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        k += 1\n",
    "        if k < minimum:\n",
    "            continue\n",
    "        if k > limit:\n",
    "            break\n",
    "        ms = row['male_eng']\n",
    "        ws = row['female_eng']\n",
    "        mc = parse(scrape(ms))\n",
    "        wc = parse(scrape(ws))\n",
    "        insert_data(index, mc, True)\n",
    "        insert_data(index, wc, False)\n",
    "        print('MC:', mc, 'WC:', wc)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTP code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import quote\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import fake_useragent\n",
    "\n",
    "session = requests.Session()\n",
    "ua = fake_useragent.FakeUserAgent()\n",
    "\n",
    "# Рискованная версия\n",
    "headers = {\n",
    "    'User-Agent': (\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
    "        'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "        'Chrome/90.0.4430.93 Safari/537.36'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Оптимальная версия\n",
    "headers = {\n",
    "    'User-Agent': (ua.random)\n",
    "}\n",
    "session.headers.update(headers)\n",
    "\n",
    "retry_params = Retry(\n",
    "    total=5,\n",
    "    status_forcelist=[429, 500, 502, 503, 504],\n",
    "    backoff_factor=1\n",
    ")\n",
    "\n",
    "adapter = HTTPAdapter(max_retries=retry_params)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)\n",
    "\n",
    "\n",
    "def scrape_and_parse(surname):\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': (ua.random)\n",
    "    }\n",
    "    session.headers.update(headers)\n",
    "\n",
    "    surname_enc = quote(surname)\n",
    "    url = f\"https://forebears.io/surnames/{surname_enc}\"\n",
    "    try:\n",
    "        print(f\"Запрос по: {url}\")\n",
    "        response = session.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                if len(cols) >= 2:\n",
    "                    country = cols[0].get_text(strip=True).lower()\n",
    "                    count = cols[1].get_text(strip=True).replace(',', '')\n",
    "                    if country in ['russia', 'россия']:\n",
    "                        return count\n",
    "                    \n",
    "        return 0\n",
    "    \n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"Ошибка HTTP на '{surname}': {http_err}\")\n",
    "        if '403' in str(http_err):\n",
    "            return -2\n",
    "        return -1\n",
    "    \n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"Сетевая ошибка на '{surname}': {req_err}\")\n",
    "        if '403' in str(req_err):\n",
    "            return -2\n",
    "        return -1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Другая ошибка на '{surname}': {e}\")\n",
    "        if '403' in str(e):\n",
    "            return -2\n",
    "        return -1\n",
    "\n",
    "\n",
    "def process_row(row):\n",
    "    ms = row['male_eng']\n",
    "    ws = row['female_eng']\n",
    "    mc = scrape_and_parse(ms)\n",
    "    wc = scrape_and_parse(ws)\n",
    "    return mc, wc\n",
    "\n",
    "\n",
    "minimum = 2720\n",
    "limit = len(df)\n",
    "\n",
    "minimum = max(minimum, 0)\n",
    "limit = max(limit, minimum+1)\n",
    "limit = min(limit, len(df))\n",
    "\n",
    "subset = df.iloc[minimum:limit]\n",
    "\n",
    "\n",
    "def main():\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_index = {\n",
    "            executor.submit(process_row, row): index for index, row in subset.iterrows()\n",
    "        }\n",
    "        for future in as_completed(future_to_index):\n",
    "            index = future_to_index[future]\n",
    "            try:\n",
    "                mc, wc = future.result()\n",
    "                if mc == -2:\n",
    "                    return\n",
    "                df.at[index, 'male_cnt'] = mc\n",
    "                df.at[index, 'female_cnt'] = wc\n",
    "                print(f'Index {index} - MC: {mc}, WC: {wc}')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"ОШИБКА {index}: {e}\")\n",
    "                if str(e).__contains__('403'):\n",
    "                    return\n",
    "                \n",
    "\n",
    "main()\n",
    "\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
